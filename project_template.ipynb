{
 "cells": [
  {
   "attachments": {
    "different%20airplanes%20on%20tarmac.jpeg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Analysis of Immigration Data in the United States\n",
    "\n",
    "### Project Summary\n",
    "\n",
    "In this project, we will be looking at the immigration data for the united states. \n",
    "By the end of this Exploratory Data Analysis (EDA) we'd be able to have some insights on following questions:\n",
    "\n",
    "* How temperature affects the volume of travellers ? \n",
    "* Which season of travel is most preferred ? \n",
    "* What sort of relationship is between the volume of travel and the number of entry ports (i.e. airports) ?\n",
    "* How the volume of travel and the demographics of various cities are dependent on each other ?\n",
    "\n",
    "#### Resources used :\n",
    "\n",
    "* **I94 Immigration Data**\n",
    "The I-94 provides a count of visitor arrivals to the United States (with stays of 1-night or more and visiting under \n",
    "certain visa types) to calculate U.S. travel and tourism volume exports\n",
    "    \n",
    "   ![different%20airplanes%20on%20tarmac.jpeg](attachment:different%20airplanes%20on%20tarmac.jpeg)\n",
    "    \n",
    "    \n",
    "    We've following files in the directory of this project:\n",
    "\n",
    "   * _countries.csv_ : table containing country codes used in the dataset, extracted from the data dictionary\n",
    "   * _i94portCodes.csv_: table containing city codes used in the dataset, extracted from the data dictionary\n",
    "\n",
    "\n",
    "\n",
    "* **World Temperature Data**: This dataset comes from Kaggle and includes the temperatures of various cities in the world from 1743 to 2013.\n",
    "\n",
    "* **U.S. City Demographic Data**: This data comes from OpenSoft. It contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000 and comes from the US Census Bureau's 2015 American Community Survey.\n",
    "\n",
    "* **Airport Code Table**: This is a simple table of airport codes and corresponding cities.\n",
    "\n",
    "\n",
    "The project follows the follow steps:\n",
    "* **Step 1**: Scope the Project and Gather Data\n",
    "    * Since the scope of the project will be highly dependent on the data, these two things happen simultaneously. In this step, we’ll:\n",
    "           \n",
    "         * Identify and gather the data we'll be using for your project \n",
    "           (at least two sources and more than 1 million rows).\n",
    "         * Explain what end use cases we'd like to prepare the data for.\n",
    "\n",
    "* **Step 2**: Explore and Assess the Data\n",
    "    * Explore the data to identify data quality issues, like missing values, duplicate data, etc.\n",
    "    * Document steps necessary to clean the data\n",
    "\n",
    "* **Step 3**: Define the Data Model\n",
    "    * Map out the conceptual data model and explain why we'd chose that model\n",
    "    * List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "* **Step 4**: Run ETL to Model the Data\n",
    "    * Create the data pipelines and the data model\n",
    "    * Include a data dictionary\n",
    "    * Run data quality checks to ensure the pipeline ran as expected\n",
    "        * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    "        * Unit tests for the scripts to ensure they are doing the right thing\n",
    "        * Source/count checks to ensure completeness\n",
    "* **Step 5**: Complete Project Write Up\n",
    "    Answer these questions:\n",
    "    * What's the goal? What queries would we want to run? How would Spark or Airflow be incorporated? Why did we choose the model we chose?\n",
    "    * Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "    * Document the steps of the process.\n",
    "    * Propose how often the data should be updated and why.\n",
    "    * Post your write-up and final data model in a GitHub repo.\n",
    "    * Include a description of how you would approach the problem differently under the following scenarios:\n",
    "        * If the data was increased by 100x.\n",
    "        * If the pipelines were run on a daily basis by 7am.\n",
    "        * If the database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary lib\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, date_add\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "##### Datasets:\n",
    "    The following datasets are used for the scope of this project:\n",
    "    \n",
    "- [x] I94 Immigration Data: This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace. [This](https://www.trade.gov/national-travel-and-tourism-office) is where the data comes from. There's a sample file so we can take a look at the data in csv format before reading it all in. We do not have to use the entire dataset, just use what we need to accomplish the goal you set at the beginning of the project.\n",
    "- [x] World Temperature Data: This dataset came from Kaggle. You can read more about it [here](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "- [x] U.S. City Demographic Data: This data comes from OpenSoft. You can read more about it [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n",
    "- [x] Airport Code Table: This is a simple table of airport codes and corresponding cities. It comes from [here](https://datahub.io/core/airport-codes#data).\n",
    "\n",
    "\n",
    "#### Accessing the datasets\n",
    "\n",
    "* Immigration Data\n",
    "    We can access the immigration data in a folder with the following path: <code>../../data/18-83510-I94-Data-2016/</code> \n",
    "    There's a file for each month of the year. An example file name is <code>i94_apr16_sub.sas7bdat.</code> Each file has a three-letter abbreviation for the month name. So a full file path for June would look like this: <code>../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat.</code> Below is what it would look like to import this file into pandas. Note: these files are large, so we'll have to think about how to process and aggregate them efficiently\n",
    "    \n",
    "    <code>fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")</code>\n",
    "    \n",
    "    \n",
    "* The most important decision for modeling with this data is thinking about the level of aggregation. Do you want to aggregate by airport by month? Or by city by year? This level of aggregation will influence how you join the data with other datasets. There isn't a right answer, it all depends on what you want your final dataset to look like.\n",
    "\n",
    "\n",
    "* Temperature Data\n",
    "\n",
    "    We can access the temperature data in a folder with the following path: <code>../../data2/.</code> There's just one file in that folder, called <code>GlobalLandTemperaturesByCity.csv.</code> Below is how you would read the file into a pandas dataframe.\n",
    "\n",
    "    <code>fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "    df = pd.read_csv(fname)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Immigration Dataset\n",
    "The immigration dataset is large, containing approximately 3m lines.\n",
    "\n",
    "We will use a subset of approx 1000 rows in a csv to explore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>721257</td>\n",
       "      <td>1481650.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20552.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20606.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>10072016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>7.368526e+08</td>\n",
       "      <td>910</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1072780</td>\n",
       "      <td>2197173.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>20556.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20635.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>10112016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CX</td>\n",
       "      <td>7.863122e+08</td>\n",
       "      <td>870</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>112205</td>\n",
       "      <td>232708.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>06302016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.547449e+10</td>\n",
       "      <td>00117</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2577162</td>\n",
       "      <td>5227851.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20575.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>07262016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LX</td>\n",
       "      <td>5.941342e+10</td>\n",
       "      <td>00008</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10930</td>\n",
       "      <td>13213.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>5.544979e+10</td>\n",
       "      <td>00109</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "5      721257  1481650.0  2016.0     4.0   577.0   577.0     ATL  20552.0   \n",
       "6     1072780  2197173.0  2016.0     4.0   245.0   245.0     SFR  20556.0   \n",
       "7      112205   232708.0  2016.0     4.0   113.0   135.0     NYC  20546.0   \n",
       "8     2577162  5227851.0  2016.0     4.0   131.0   131.0     CHI  20572.0   \n",
       "9       10930    13213.0  2016.0     4.0   116.0   116.0     LOS  20545.0   \n",
       "\n",
       "   i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "0      1.0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN   \n",
       "1      1.0      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN   \n",
       "2      1.0      FL  20571.0    76.0      2.0    1.0  20160407      NaN   NaN   \n",
       "3      1.0      CA  20581.0    25.0      2.0    1.0  20160428      DOH   NaN   \n",
       "4      3.0      NY  20553.0    19.0      2.0    1.0  20160406      NaN   NaN   \n",
       "5      1.0      GA  20606.0    51.0      2.0    1.0  20160408      NaN   NaN   \n",
       "6      1.0      CA  20635.0    48.0      2.0    1.0  20160412      NaN   NaN   \n",
       "7      1.0      NY  20554.0    33.0      2.0    1.0  20160402      NaN   NaN   \n",
       "8      1.0      IL  20575.0    39.0      2.0    1.0  20160428      NaN   NaN   \n",
       "9      1.0      CA  20553.0    35.0      2.0    1.0  20160401      NaN   NaN   \n",
       "\n",
       "  entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       G       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       G       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "2       G       O      NaN       M   1940.0  07052016      M     NaN      LH   \n",
       "3       G       O      NaN       M   1991.0  10272016      M     NaN      QR   \n",
       "4       Z       K      NaN       M   1997.0  07042016      F     NaN     NaN   \n",
       "5       T       N      NaN       M   1965.0  10072016      M     NaN      DL   \n",
       "6       T       O      NaN       M   1968.0  10112016      F     NaN      CX   \n",
       "7       G       O      NaN       M   1983.0  06302016      F     NaN      BA   \n",
       "8       O       O      NaN       M   1977.0  07262016    NaN     NaN      LX   \n",
       "9       O       O      NaN       M   1981.0  06292016    NaN     NaN      AA   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  \n",
       "3  9.478970e+10  00739       B2  \n",
       "4  4.232257e+10   LAND       WT  \n",
       "5  7.368526e+08    910       B2  \n",
       "6  7.863122e+08    870       B2  \n",
       "7  5.547449e+10  00117       WT  \n",
       "8  5.941342e+10  00008       WT  \n",
       "9  5.544979e+10  00109       WT  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here\n",
    "df_immig_sample = pd.read_csv('immigration_data_sample.csv')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "df_immig_sample.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The definition of the fields is included in the file <code>I94_SAS_Labels_Descriptions.SAS</code>\n",
    "\n",
    "We'll primarily be working with the following fields:\n",
    "\n",
    "- [x] i94cit : country of citizenship\n",
    "- [x] i94res : country of residence\n",
    "- [x] i94port: arrival airport\n",
    "- [x] arrdate: arrival date. \n",
    "- [x] i94mode\n",
    "- [x] i94addr\n",
    "- [x] depdate\n",
    "- [x] i94bir\n",
    "- [x] i94visa\n",
    "- [x] occup\n",
    "- [x] biryear\n",
    "- [x] dtaddto\n",
    "- [x] gender\n",
    "- [x] insnum\n",
    "- [x] airline\n",
    "- [x] admnum\n",
    "- [x] fltno\n",
    "- [x] visatype\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Adding data dictionaries\n",
    "In the next step, we will add details from the data dictionnary.\n",
    "\n",
    "These will replace the codes in our data model since we work with denormalized data models.\n",
    "\n",
    "Adding dictionary for columns I94CIT & I94RES (countries.csv) which we assume corresponds to country of citizenship and country of residence of the travelers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code      country\n",
       "0   582      MEXICO \n",
       "1   236  AFGHANISTAN\n",
       "2   101      ALBANIA\n",
       "3   316      ALGERIA\n",
       "4   102      ANDORRA"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading and vizualising CountryCodes\n",
    "\n",
    "df_countryCodes = pd.read_csv('countries.csv')\n",
    "df_countryCodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>location</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code                  location state\n",
       "0  ALC                     ALCAN    AK\n",
       "1  ANC                 ANCHORAGE    AK\n",
       "2  BAR  BAKER AAF - BAKER ISLAND    AK\n",
       "3  DAC             DALTONS CACHE    AK\n",
       "4  PIZ    DEW STATION PT LAY DEW    AK"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding a correspondance table between i94port codes and city that was the port of entry (i94portCodes.csv)\n",
    "#vizualising top 5 rows\n",
    "\n",
    "i94portCodes = pd.read_csv('i94portCodes.csv')\n",
    "i94portCodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### World Temperature data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading temperature from file:\n",
    "\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temperature = pd.read_csv(fname)\n",
    "\n",
    "df_temperature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographic Data\n",
    "Demographic data\n",
    "Our dataset contains details on the reason for traveling. \n",
    "We want to see if there is a connection between the flow of immigration and the demographic data of various US cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here\n",
    "df_demographics = pd.read_csv('us-cities-demographics.csv', sep=';')\n",
    "\n",
    "# See the first few rows\n",
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Airport data\n",
    "\n",
    "Since airports are the point of entry for these immigrants, \n",
    "we will include airport information in our data.\n",
    "\n",
    "This data will allow us to connect airport data to the airport codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data here\n",
    "df_airports = pd.read_csv('airport-codes_csv.csv')\n",
    "\n",
    "# see the first few rows\n",
    "df_airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Full immigration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "df_immigration = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096313\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_immigration.count())\n",
    "df_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    " #write to parquet\n",
    "# df_immigration.write.parquet(\"sas_data\")\n",
    "# df_immigration=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "\n",
    "- [x] Perform an EDA on data quality issues (eg: missing values, duplicates etc)\n",
    "- [x] Clean the data and document the steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Performing Step 2 on Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "3096313\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in immigration dataset:\n",
    "\n",
    "df_immigration.show(5)\n",
    "\n",
    "# print the number of rows for this dataset:\n",
    "print(df_immigration.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT cicid)|\n",
      "+---------------------+\n",
      "|              3096313|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Temporary View to check if cicid can be used as a primary key\n",
    "df_immigration.createOrReplaceTempView(\"immig_table\")\n",
    "\n",
    "# Checking this data via spark query\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT (DISTINCT cicid)\n",
    "FROM immig_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|len|\n",
      "+---+\n",
      "|  3|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The data dictionary for i94port has all the codes which are 3 character long, checking if the iimig_table has similar lenght for i94port attribute\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT LENGTH (i94port) AS len\n",
    "FROM immig_table\n",
    "GROUP BY len\n",
    "\"\"\").show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since the length is same, we can join these without further processsing.\n",
    "\n",
    "Arrival date field (arrdate) can be converted to useable. \n",
    "Dates in SAS corresponds to the no.of days since 1960-01-01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# adding arrdate to 1960-01-01\n",
    "\n",
    "df_immigration = spark.sql(\"SELECT *, date_add(to_date('1960-01-01'), arrdate) AS arrival_date FROM immig_table\")\n",
    "df_immigration.createOrReplaceTempView(\"immig_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Replace the data in the I94VISA columns\n",
    "Categories:\n",
    "\n",
    "1 = Business  \n",
    "2 = Pleasure  \n",
    "3 = Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT *, CASE \n",
    "                        WHEN i94visa = 1.0 THEN 'Business' \n",
    "                        WHEN i94visa = 2.0 THEN 'Pleasure'\n",
    "                        WHEN i94visa = 3.0 THEN 'Student'\n",
    "                        ELSE 'N/A' END AS visa_type \n",
    "                        \n",
    "                FROM immig_table\"\"\").createOrReplaceTempView(\"immig_table\")\n",
    "\n",
    "spark.sql(\"\"\"SELECT *, CASE \n",
    "                        WHEN depdate >= 1.0 THEN date_add(to_date('1960-01-01'), depdate)\n",
    "                        WHEN depdate IS NULL THEN NULL\n",
    "                        ELSE 'N/A' END AS departure_date \n",
    "                        \n",
    "                FROM immig_table\"\"\").createOrReplaceTempView(\"immig_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking if there are no NA values\n",
    "\n",
    "spark.sql(\"SELECT count(*) FROM immig_table WHERE departure_date = 'N/A'\").show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There is a possibility of departure_date > arrival_date.\n",
    "In next steps, we check this and find a probable solution, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     375|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of cases where dep date > arrival date?\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM immig_table\n",
    "WHERE departure_date <= arrival_date\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since the number of records are quite lower,and we can not manipulate these dates because this would affect outcome of the analysis.\n",
    "So we would drop these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dropping these 375 records.\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM immig_table\n",
    "WHERE departure_date >= arrival_date\n",
    "\"\"\").createOrReplaceTempView(\"immig_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Finally, we'd check on number of distinct values we get in the arrival and departure dates to decide \n",
    "if we need to merge our two sets for the time dimension table we'll be using in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|count(DISTINCT departure_date)|\n",
      "+------------------------------+\n",
      "|                           174|\n",
      "+------------------------------+\n",
      "\n",
      "+----------------------------+\n",
      "|count(DISTINCT arrival_date)|\n",
      "+----------------------------+\n",
      "|                          30|\n",
      "+----------------------------+\n",
      "\n",
      "+------------------------------+\n",
      "|count(DISTINCT departure_date)|\n",
      "+------------------------------+\n",
      "|                            29|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check distinct departure dates\n",
    "spark.sql(\"SELECT COUNT (DISTINCT departure_date) FROM immig_table \").show()\n",
    "\n",
    "# check distinct arrival dates\n",
    "spark.sql(\"SELECT COUNT (DISTINCT arrival_date) FROM immig_table \").show()\n",
    "\n",
    "# check the common values between the two sets\n",
    "spark.sql(\"\"\"   SELECT COUNT(DISTINCT departure_date) \n",
    "                FROM immig_table \n",
    "                WHERE departure_date IN (\n",
    "                    SELECT DISTINCT arrival_date FROM immig_table\n",
    "                ) \n",
    "                \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We'd consider to merge the two datasets in order to include\n",
    "both departure and arrival dates for our dim table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Next, we'd want to understand the various arrival modes**\n",
    "\n",
    "The arrival modes definition as per the dictonary is:\n",
    "\n",
    "1 = 'Air'  \n",
    "2 = 'Sea'  \n",
    "3 = 'Land'  \n",
    "9 = 'Not reported' We will only keep Air arrival since we're joining this with airport datasets  \n",
    "\n",
    "We will consider only arrival by air to ensure that our dataset can work with the airports dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|i94mode|count(1)|\n",
      "+-------+--------+\n",
      "|   null|     238|\n",
      "|    1.0| 2871184|\n",
      "|    3.0|   61572|\n",
      "|    2.0|   17970|\n",
      "|    9.0|    2517|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what are the various arrival modes?\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT i94mode, count(*)\n",
    "FROM immig_table\n",
    "GROUP BY i94mode\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Analysing missing values in the birth year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# null values in biryear\n",
    "spark.sql(\"SELECT COUNT(biryear) FROM immig_table WHERE biryear IS NULL\").show()\n",
    "\n",
    "#min and max years\n",
    "spark.sql(\"SELECT MAX(biryear), MIN(biryear) FROM immig_table WHERE biryear IS NOT NULL\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since the birth year is available for each row, we can compute the age.\n",
    "We can run a check on birth year column as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check for null vals in birth year column\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM immig_table\n",
    "WHERE i94bir IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's see if derived age from birth year would match with the one in i94bir.\n",
    "We could use birth year for age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|difference|count(1)|\n",
      "+----------+--------+\n",
      "|       0.0| 2953435|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT (2016-biryear)-i94bir AS difference, count(*) FROM immig_table WHERE i94bir IS NOT NULL GROUP BY difference\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Analysing gender column to see if the data is useable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|gender|count(1)|\n",
      "+------+--------+\n",
      "|     F| 1228646|\n",
      "|  null|  407456|\n",
      "|     M| 1316305|\n",
      "|     U|     238|\n",
      "|     X|     836|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gender count\n",
    "spark.sql(\"\"\"\n",
    "SELECT gender, count(*) \n",
    "FROM immig_table\n",
    "GROUP BY gender\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In order to handle the null values in gender column, we'd filter out the rows where gender data is missing/incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# handling gender data\n",
    "spark.sql(\"\"\"SELECT * FROM immig_table WHERE gender IN ('F', 'M')\"\"\").createOrReplaceTempView(\"immig_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Analysing citizenship and residence column to see if the data is useable and cleaning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  114019|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#citizenship countries\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(*) \n",
    "FROM immig_table\n",
    "WHERE i94cit IS NULL\n",
    "\"\"\").show()\n",
    "\n",
    "#residence countries\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(*) \n",
    "FROM immig_table\n",
    "WHERE i94res IS NULL\n",
    "\"\"\").show()\n",
    "\n",
    "#reported address\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(*) \n",
    "FROM immig_table\n",
    "WHERE i94addr IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "address or state of resident is largely missing and non useable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Running a check on Visa type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# null vals in visa\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM immig_table\n",
    "WHERE visatype IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The definitions for various detailed visa types are listed below. Some are unknown. We couldn't find definitions for all the visa types. We will retain the details since it might be of interest from a demographic standpoint\n",
    "\n",
    "* B1 visa is for business visits valid for up to a year\n",
    "* B2 visa is for pleasure visits valid for up to a year\n",
    "* CP could not find a definition\n",
    "* E2 investor visas allows foreign investors to enter and work inside of the United States based on a substantial investment\n",
    "* F1 visas are used by non-immigrant students for Academic and Language training Courses.\n",
    "* F2 visas are used by the dependents of F1 visa holders\n",
    "* GMT could not find a definition\n",
    "* M1 for students enrolled in non-academic or “vocational study”. Mechanical, language, cooking classes, etc...\n",
    "* WB Waiver Program (WT/WB Status) travel to the United States for tourism or business for stays of 90 days or less without obtaining a visa.\n",
    "* WT Waiver Program (WT/WB Status) travel to the United States for tourism or business for stays of 90 days or less without obtaining a visa.\n",
    "\n",
    "Let's check the visa type by category\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+\n",
      "|visa_type|visatype|count(1)|\n",
      "+---------+--------+--------+\n",
      "| Business|      B1|  186610|\n",
      "| Business|      E1|    3182|\n",
      "| Business|      E2|   16227|\n",
      "| Business|     GMB|     132|\n",
      "| Business|       I|    2962|\n",
      "| Business|      I1|     214|\n",
      "| Business|      WB|  185857|\n",
      "| Pleasure|      B2|  967988|\n",
      "| Pleasure|      CP|   11785|\n",
      "| Pleasure|     CPL|       8|\n",
      "| Pleasure|     GMT|   79454|\n",
      "| Pleasure|     SBP|       2|\n",
      "| Pleasure|      WT| 1060229|\n",
      "|  Student|      F1|   27789|\n",
      "|  Student|      F2|    1774|\n",
      "|  Student|      M1|     708|\n",
      "|  Student|      M2|      30|\n",
      "+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# types of visa\n",
    "spark.sql(\"\"\"\n",
    "SELECT visa_type, visatype, count(*)\n",
    "FROM immig_table\n",
    "GROUP BY visa_type, visatype\n",
    "ORDER BY visa_type, visatype\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since we have little information besides the detailed visa type and the aggregate visa type, we will simply keep the information in our dimension table.\n",
    "\n",
    "Moving to occupation field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|occup|      n|\n",
      "+-----+-------+\n",
      "| null|2538838|\n",
      "|  STU|   3275|\n",
      "|  OTH|    508|\n",
      "|  NRR|    299|\n",
      "|  MKT|    262|\n",
      "|  EXA|    175|\n",
      "|  ULS|    142|\n",
      "|  ADM|    119|\n",
      "|  GLS|    119|\n",
      "|  TIE|    108|\n",
      "|  MVC|     58|\n",
      "|  ENO|     55|\n",
      "|  CEO|     53|\n",
      "|  TIP|     49|\n",
      "|  LLJ|     45|\n",
      "|  RET|     44|\n",
      "|  CMP|     43|\n",
      "|  PHS|     42|\n",
      "|  UNP|     33|\n",
      "|  HMK|     30|\n",
      "+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# occupation category count\n",
    "spark.sql(\"\"\"\n",
    "SELECT occup, COUNT(*) AS n\n",
    "FROM immig_table\n",
    "GROUP BY occup\n",
    "ORDER BY n DESC, occup\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Several fields are null values.\n",
    "We won't be using it in our data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Performing Step 2 on Temperature data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check first few rows\n",
    "df_temperature.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    }
   ],
   "source": [
    "#check unique count of Countries:\n",
    "print(df_temperature['Country'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data is exhaustive for 159 countries from year 1743.  \n",
    "Restricting the dataset to USA only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Keep only data for the United States\n",
    "df_temperature = df_temperature[df_temperature['Country']=='United States']\n",
    "\n",
    "# Convert the date to datetime objects\n",
    "df_temperature['convertedDate'] = pd.to_datetime(df_temperature.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Excluding data prior to 1950, since commercial air travel developed after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2013-09-01 00:00:00')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all dates prior to 1950\n",
    "df_temperature=df_temperature[df_temperature['convertedDate']>\"1950-01-01\"].copy()\n",
    "\n",
    "# Let's check the most recent date in the dataset\n",
    "df_temperature['convertedDate'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                               0\n",
       "AverageTemperature               1\n",
       "AverageTemperatureUncertainty    1\n",
       "City                             0\n",
       "Country                          0\n",
       "Latitude                         0\n",
       "Longitude                        0\n",
       "convertedDate                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check for null values.\n",
    "df_temperature.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>convertedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287781</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>United States</td>\n",
       "      <td>61.88N</td>\n",
       "      <td>151.13W</td>\n",
       "      <td>2013-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "287781  2013-09-01                 NaN                            NaN   \n",
       "\n",
       "             City        Country Latitude Longitude convertedDate  \n",
       "287781  Anchorage  United States   61.88N   151.13W    2013-09-01  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#null values on average temp\n",
    "df_temperature[df_temperature.AverageTemperature.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We'd use the combination of city and date as a primary key.\n",
    "Since missing value of Anchorage would affect joining with immmigration dataset.\n",
    "\n",
    "Imputing temp values for Anchorage could create outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's check on multiple entries for a given city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>convertedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405836</th>\n",
       "      <td>1950-02-01</td>\n",
       "      <td>1.655</td>\n",
       "      <td>0.057</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "      <td>1950-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405837</th>\n",
       "      <td>1950-03-01</td>\n",
       "      <td>3.871</td>\n",
       "      <td>0.232</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "      <td>1950-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405838</th>\n",
       "      <td>1950-04-01</td>\n",
       "      <td>9.678</td>\n",
       "      <td>0.191</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "      <td>1950-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405839</th>\n",
       "      <td>1950-05-01</td>\n",
       "      <td>16.786</td>\n",
       "      <td>0.234</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "      <td>1950-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405840</th>\n",
       "      <td>1950-06-01</td>\n",
       "      <td>21.548</td>\n",
       "      <td>0.222</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "      <td>1950-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "405836  1950-02-01               1.655                          0.057   \n",
       "405837  1950-03-01               3.871                          0.232   \n",
       "405838  1950-04-01               9.678                          0.191   \n",
       "405839  1950-05-01              16.786                          0.234   \n",
       "405840  1950-06-01              21.548                          0.222   \n",
       "\n",
       "             City        Country Latitude Longitude convertedDate  \n",
       "405836  Arlington  United States   39.38N    76.99W    1950-02-01  \n",
       "405837  Arlington  United States   39.38N    76.99W    1950-03-01  \n",
       "405838  Arlington  United States   39.38N    76.99W    1950-04-01  \n",
       "405839  Arlington  United States   39.38N    76.99W    1950-05-01  \n",
       "405840  Arlington  United States   39.38N    76.99W    1950-06-01  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature[df_temperature[['City','convertedDate']].duplicated()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>convertedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402597</th>\n",
       "      <td>1950-02-01</td>\n",
       "      <td>11.144</td>\n",
       "      <td>0.199</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>96.70W</td>\n",
       "      <td>1950-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405836</th>\n",
       "      <td>1950-02-01</td>\n",
       "      <td>1.655</td>\n",
       "      <td>0.057</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "      <td>1950-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "402597  1950-02-01              11.144                          0.199   \n",
       "405836  1950-02-01               1.655                          0.057   \n",
       "\n",
       "             City        Country Latitude Longitude convertedDate  \n",
       "402597  Arlington  United States   32.95N    96.70W    1950-02-01  \n",
       "405836  Arlington  United States   39.38N    76.99W    1950-02-01  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check on temperature for Arlington(multiple entries)\n",
    "df_temperature[(df_temperature['City'] == 'Arlington') & (df_temperature.dt == '1950-02-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Due to temperature being measured in multiple location for each city.  \n",
    "***When creating the dimension table, we'll compute the average temperatures and uncertainties per city***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Performing Step 2 on Airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading few lines of airport dataset\n",
    "df_airports.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iso_country\n",
       "AD        2\n",
       "AE       57\n",
       "AF       64\n",
       "AG        3\n",
       "AI        1\n",
       "AL       13\n",
       "AM       13\n",
       "AO      104\n",
       "AQ       27\n",
       "AR      848\n",
       "AS        4\n",
       "AT      145\n",
       "AU     1963\n",
       "AW        1\n",
       "AZ       35\n",
       "BA       15\n",
       "BB        6\n",
       "BD       16\n",
       "BE      146\n",
       "BF       51\n",
       "BG      134\n",
       "BH        4\n",
       "BI        7\n",
       "BJ       10\n",
       "BL        1\n",
       "BM        3\n",
       "BN        2\n",
       "BO      197\n",
       "BQ        3\n",
       "BR     4334\n",
       "      ...  \n",
       "TM       21\n",
       "TN       15\n",
       "TO        6\n",
       "TR      124\n",
       "TT        3\n",
       "TV        3\n",
       "TW       65\n",
       "TZ      207\n",
       "UA      191\n",
       "UG       38\n",
       "UM        6\n",
       "US    22757\n",
       "UY       54\n",
       "UZ      176\n",
       "VA        1\n",
       "VC        6\n",
       "VE      592\n",
       "VG        3\n",
       "VI        9\n",
       "VN       50\n",
       "VU       32\n",
       "WF        2\n",
       "WS        4\n",
       "XK        6\n",
       "YE       25\n",
       "YT        1\n",
       "ZA      489\n",
       "ZM      103\n",
       "ZW      138\n",
       "ZZ        7\n",
       "Name: iso_country, Length: 243, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the countries wherein these Airports are located\n",
    "df_airports.groupby('iso_country')['iso_country'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "continent\n",
       "AF    247\n",
       "Name: continent, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the missing country values\n",
    "df_airports[df_airports['iso_country'].isna()].groupby('continent')['continent'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "All the missing country data is for airports based in Africa.  \n",
    "We may drop these data points safely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Since all missing values are in africa, we'd remove them from the dataset\n",
    "df_airports = df_airports[df_airports['iso_country'].fillna('').str.upper().str.contains('US')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident               0\n",
       "type                0\n",
       "name                0\n",
       "elevation_ft      239\n",
       "continent       22756\n",
       "iso_country         0\n",
       "iso_region          0\n",
       "municipality      102\n",
       "gps_code         1773\n",
       "iata_code       20738\n",
       "local_code       1521\n",
       "coordinates         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We recheck null values:\n",
    "df_airports.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The ident code cannot be used to join airport data with the immigration set. \n",
    "\n",
    "Though, the airport linked to the ident, local or iata code columns are very different from the definitions found in the data dictionary.  \n",
    "**Therefore we must use the municipality names to join our datasets.**\n",
    "\n",
    "From our previous validation, we know that we have 50 values missing from our dataset. \n",
    "\n",
    "Running a quick check on these missing values to see if we can get the municipality name through some other means\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>15SD</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Watertown / Brownlee Heliport</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-SD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15SD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.1080899239, 44.883264878199995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>21ID</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Nordman / Phillabaum Heliport</td>\n",
       "      <td>2440.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-116.871174574, 48.631483378700004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>3ME7</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Peru / Destiny Cove SPB</td>\n",
       "      <td>580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-ME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3ME7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.396957, 44.460597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7653</th>\n",
       "      <td>6XA4</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Zadow Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6XA4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-95.954353809, 29.991738550900003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7887</th>\n",
       "      <td>74xa</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Gun Barrel City Airpark</td>\n",
       "      <td>385.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74XA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-96.1456650496, 32.3551499558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ident           type                           name  elevation_ft  \\\n",
       "1544  15SD       heliport  Watertown / Brownlee Heliport        1720.0   \n",
       "2452  21ID       heliport  Nordman / Phillabaum Heliport        2440.0   \n",
       "4401  3ME7  seaplane_base        Peru / Destiny Cove SPB         580.0   \n",
       "7653  6XA4  small_airport                 Zadow Airstrip           NaN   \n",
       "7887  74xa  small_airport        Gun Barrel City Airpark         385.0   \n",
       "\n",
       "     continent iso_country iso_region municipality gps_code iata_code  \\\n",
       "1544       NaN          US      US-SD          NaN     15SD       NaN   \n",
       "2452       NaN          US      US-ID          NaN     21ID       NaN   \n",
       "4401       NaN          US      US-ME          NaN     3ME7       NaN   \n",
       "7653       NaN          US      US-TX          NaN     6XA4       NaN   \n",
       "7887       NaN          US      US-TX          NaN     74XA       NaN   \n",
       "\n",
       "     local_code                         coordinates  \n",
       "1544        NaN  -97.1080899239, 44.883264878199995  \n",
       "2452        NaN  -116.871174574, 48.631483378700004  \n",
       "4401        NaN               -70.396957, 44.460597  \n",
       "7653        NaN   -95.954353809, 29.991738550900003  \n",
       "7887        NaN       -96.1456650496, 32.3551499558  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if municipality is available for all the airports\n",
    "df_airports[df_airports.municipality.isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data wherein we've null values is not useable in a way that could be automated if we were building a pipeline.  \n",
    "We'd remove them from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating a copy of this dataset\n",
    "df_airports = df_airports[~df_airports['municipality'].isna()].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We convert the municipality column to upper case in order to be able to join it with our other datasets.\n",
    "df_airports.municipality = df_airports.municipality.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iso_region\n",
       "US-AK      823\n",
       "US-AL      360\n",
       "US-AR      405\n",
       "US-AZ      355\n",
       "US-CA     1082\n",
       "US-CO      502\n",
       "US-CT      164\n",
       "US-DC       21\n",
       "US-DE       57\n",
       "US-FL      966\n",
       "US-GA      521\n",
       "US-HI       61\n",
       "US-IA      338\n",
       "US-ID      312\n",
       "US-IL      899\n",
       "US-IN      696\n",
       "US-KS      438\n",
       "US-KY      254\n",
       "US-LA      590\n",
       "US-MA      254\n",
       "US-MD      257\n",
       "US-ME      207\n",
       "US-MI      545\n",
       "US-MN      568\n",
       "US-MO      578\n",
       "US-MS      279\n",
       "US-MT      327\n",
       "US-NC      473\n",
       "US-ND      321\n",
       "US-NE      309\n",
       "US-NH      179\n",
       "US-NJ      436\n",
       "US-NM      197\n",
       "US-NV      154\n",
       "US-NY      664\n",
       "US-OH      797\n",
       "US-OK      536\n",
       "US-OR      492\n",
       "US-PA      912\n",
       "US-RI       35\n",
       "US-SC      217\n",
       "US-SD      210\n",
       "US-TN      355\n",
       "US-TX     2265\n",
       "US-U-A       4\n",
       "US-UT      168\n",
       "US-VA      505\n",
       "US-VT      102\n",
       "US-WA      575\n",
       "US-WI      623\n",
       "US-WV      140\n",
       "US-WY      127\n",
       "Name: iso_region, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check count of iso region\n",
    "df_airports.groupby('iso_region')['iso_region'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "U-A seems like an error. \n",
    "State is used in combination with city name to join with city demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Checking len of iso regions(>5 charac)\n",
    "df_airports['len'] = df_airports[\"iso_region\"].apply(len)\n",
    "\n",
    "# remove the codes that are incorrect i,e longer than 5 charc.\n",
    "df_airports = df_airports[df_airports['len']==5].copy()\n",
    "\n",
    "# extract the state code\n",
    "df_airports['state'] = df_airports['iso_region'].str.strip().str.split(\"-\", n = 1, expand = True)[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Performing Step 2 on Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick view on data\n",
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# converting city to upper case & trim whitespace\n",
    "df_demographics.City = df_demographics.City.str.upper().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "State                      0\n",
       "Median Age                 0\n",
       "Male Population            3\n",
       "Female Population          3\n",
       "Total Population           0\n",
       "Number of Veterans        13\n",
       "Foreign-born              13\n",
       "Average Household Size    16\n",
       "State Code                 0\n",
       "Race                       0\n",
       "Count                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "df_demographics.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data has lesser null values.  \n",
    "No fix needed as of now, incase while loading dimension tables, we'd fix these rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove any leading or trailing spaces and convert to upper case\n",
    "df_demographics.City = df_demographics.City.str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>WILMINGTON</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>36.4</td>\n",
       "      <td>32680.0</td>\n",
       "      <td>39277.0</td>\n",
       "      <td>71957</td>\n",
       "      <td>3063.0</td>\n",
       "      <td>3336.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>DE</td>\n",
       "      <td>Asian</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>LAKEWOOD</td>\n",
       "      <td>California</td>\n",
       "      <td>39.9</td>\n",
       "      <td>41523.0</td>\n",
       "      <td>40069.0</td>\n",
       "      <td>81592</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>18274.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>CA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>24987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>GLENDALE</td>\n",
       "      <td>California</td>\n",
       "      <td>42.1</td>\n",
       "      <td>98181.0</td>\n",
       "      <td>102844.0</td>\n",
       "      <td>201025</td>\n",
       "      <td>4448.0</td>\n",
       "      <td>111510.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "      <td>146718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>SPRINGFIELD</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>31.8</td>\n",
       "      <td>74744.0</td>\n",
       "      <td>79592.0</td>\n",
       "      <td>154336</td>\n",
       "      <td>5723.0</td>\n",
       "      <td>16226.0</td>\n",
       "      <td>2.81</td>\n",
       "      <td>MA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>5606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>BLOOMINGTON</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>23.5</td>\n",
       "      <td>40588.0</td>\n",
       "      <td>43227.0</td>\n",
       "      <td>83815</td>\n",
       "      <td>2368.0</td>\n",
       "      <td>10033.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>IN</td>\n",
       "      <td>Asian</td>\n",
       "      <td>9801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "177   WILMINGTON       Delaware        36.4          32680.0   \n",
       "210     LAKEWOOD     California        39.9          41523.0   \n",
       "238     GLENDALE     California        42.1          98181.0   \n",
       "300  SPRINGFIELD  Massachusetts        31.8          74744.0   \n",
       "549  BLOOMINGTON        Indiana        23.5          40588.0   \n",
       "\n",
       "     Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "177            39277.0             71957              3063.0        3336.0   \n",
       "210            40069.0             81592              4094.0       18274.0   \n",
       "238           102844.0            201025              4448.0      111510.0   \n",
       "300            79592.0            154336              5723.0       16226.0   \n",
       "549            43227.0             83815              2368.0       10033.0   \n",
       "\n",
       "     Average Household Size State Code                Race   Count  \n",
       "177                    2.45         DE               Asian    1193  \n",
       "210                    3.13         CA  Hispanic or Latino   24987  \n",
       "238                    2.69         CA               White  146718  \n",
       "300                    2.81         MA               Asian    5606  \n",
       "549                    2.33         IN               Asian    9801  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check on primary key: if the combination of city name and race would work\n",
    "\n",
    "df_demographics[df_demographics[['City','Race']].duplicated()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>WILMINGTON</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>52346.0</td>\n",
       "      <td>63601.0</td>\n",
       "      <td>115947</td>\n",
       "      <td>5908.0</td>\n",
       "      <td>7401.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>3152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>WILMINGTON</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>36.4</td>\n",
       "      <td>32680.0</td>\n",
       "      <td>39277.0</td>\n",
       "      <td>71957</td>\n",
       "      <td>3063.0</td>\n",
       "      <td>3336.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>DE</td>\n",
       "      <td>Asian</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           City           State  Median Age  Male Population  \\\n",
       "102  WILMINGTON  North Carolina        35.5          52346.0   \n",
       "177  WILMINGTON        Delaware        36.4          32680.0   \n",
       "\n",
       "     Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "102            63601.0            115947              5908.0        7401.0   \n",
       "177            39277.0             71957              3063.0        3336.0   \n",
       "\n",
       "     Average Household Size State Code   Race  Count  \n",
       "102                    2.24         NC  Asian   3152  \n",
       "177                    2.45         DE  Asian   1193  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# city & race combination could misguide as primary key\n",
    "df_demographics[(df_demographics.City == 'WILMINGTON') & (df_demographics.Race == 'Asian')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, State, Median Age, Male Population, Female Population, Total Population, Number of Veterans, Foreign-born, Average Household Size, State Code, Race, Count]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# introducing the combination of city, state & race\n",
    "df_demographics[df_demographics[['City', 'State','Race']].duplicated()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since there are no duplicate rows when we use the combination of city, state and race.  \n",
    "We'd use this as our primary key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Define the Data Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "3.1 Conceptual Data Model  \n",
    "\n",
    "Since we're interested in the flow of travellers through the united states. \n",
    "\n",
    "The i94 data will serve as our fact table. Our fact_immigration table will be :\n",
    "\n",
    "* cicid,\n",
    "* citizenship_country,\n",
    "* residence_country,\n",
    "* city,\n",
    "* state,\n",
    "* arrival_date,\n",
    "* departure_date,\n",
    "* age,\n",
    "* visa_type,\n",
    "* detailed_visa_type,  \n",
    "\n",
    "For our dimension tables, since our dataset only contains one month of data we will keep a record of the daily entries and provide the uses with four dimensions to aggregate our data:\n",
    "\n",
    "***dim_time*** : To aggregate the data using various time units: The fields available will be:\n",
    "\n",
    "* date,\n",
    "* year,\n",
    "* month,\n",
    "* day,\n",
    "* week,\n",
    "* weekday,\n",
    "* dayofyear\n",
    "\n",
    "***dim_airports*** : Used to determine the areas with the largest flow of travelers. Fields included will be:\n",
    "\n",
    "* ident,\n",
    "* type,\n",
    "* name,\n",
    "* elevation_ft,\n",
    "* state,\n",
    "* municipality,\n",
    "* iata_code  \n",
    "\n",
    "***dim_city_demographics***: To look at the demographic data of the areas with the most travelers and potentially look at the impact of the flow of travellers on the demographic data (if it were updated on a regular basis). The fields available will be:\n",
    "\n",
    "* City,\n",
    "* state,\n",
    "* median_age,\n",
    "* male_population,\n",
    "* female_population,\n",
    "* total population\n",
    "* Foreign_born,\n",
    "* Average_Household_Size,\n",
    "* Race,\n",
    "* Count\n",
    "\n",
    "\n",
    "***dim_temperatures***: to look at the temperature data of the cities where traveller entry and departure is being reported. The fields included will be:\n",
    "\n",
    "* date,\n",
    "* City,\n",
    "* average temperature,\n",
    "* average temperature uncertainty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "****3.2 Mapping Out Data Pipelines****  \n",
    "\n",
    "Brief on data cleaning steps:  \n",
    "\n",
    "***Data Extraction:*** \n",
    "- [x] Load all the datasets from CSV and SAS data files;\n",
    "\n",
    "***Data Transformation and Loading:*** \n",
    "\n",
    "****fact_immigration:****\n",
    "\n",
    "- [x] Drop rows where the mode of arrival is not air travel\n",
    "- [x] Drop rows with incorrect gender data\n",
    "- [x] convert arrival and departure dates;\n",
    "- [x] replace country codes with the character string equivalents\n",
    "- [x] replace visa_type with character string\n",
    "- [x] replace port of entry with city and state\n",
    "- [x] filter out any row where the port of entry is not in the US\n",
    "- [x] compute age in a new row using birth year and year of our current date.\n",
    "- [x] insert data into our fact table\n",
    "- [x] Write to parquet\n",
    "\n",
    "****dim_temperature:****\n",
    "\n",
    "- [x] For the temperature table, drop all data for cities outside the united states;\n",
    "- [x] For the temperature table, drop all data for dates before 1950 since airtravel wasn't possible before that date;\n",
    "- [x] Convert city to upper case\n",
    "- [x] Compute the average temperature and uncertainty over date+city partitions\n",
    "- [x] Insert into the temperature table as is since our dataset since our dataset may include new cities in future dates;\n",
    "- [x] Write to parquet\n",
    "\n",
    "****dim_time:****\n",
    "- [x] Get all the arrival dates from the immigration data_set;\n",
    "- [x] extract year, month, day, week from the date and insert all the values in the dim_time table;\n",
    "- [x] Write to parquet\n",
    "\n",
    "****dim_airports:****\n",
    "- [x] Remove all non us airports\n",
    "- [x] Remove all invalid port of entries, ie: ['closed', 'heliport', 'seaplane_base', 'balloonport']\n",
    "- [x] Remove all rows where municipalities are missing.\n",
    "- [x] Convert municipality to upper case\n",
    "- [x] Insert to our table\n",
    "- [x] Write to parquet\n",
    "\n",
    "****dim_city_demographics:****\n",
    "- [x] Convert to city names to upper case\n",
    "- [x] Insert to our table\n",
    "- [x] Write to parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1 Create the data model\n",
    "Spark automatically reads all fields as strings in our CSV files \n",
    "whereas pandas usually correctly autodectects the data types. \n",
    "\n",
    "We'll read all the csv files using pandas dataframes and then convert them to spark dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reading demographics\n",
    "df_demographics_spark = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load('us-cities-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking at schema of this read\n",
    "df_demographics_spark.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       object\n",
       "State                      object\n",
       "Median Age                float64\n",
       "Male Population           float64\n",
       "Female Population         float64\n",
       "Total Population            int64\n",
       "Number of Veterans        float64\n",
       "Foreign-born              float64\n",
       "Average Household Size    float64\n",
       "State Code                 object\n",
       "Race                       object\n",
       "Count                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for datatypes:\n",
    "df_demographics.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: double (nullable = true)\n",
      " |-- Female Population: double (nullable = true)\n",
      " |-- Total Population: long (nullable = true)\n",
      " |-- Number of Veterans: double (nullable = true)\n",
      " |-- Foreign-born: double (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating data frame\n",
    "spark.createDataFrame(df_demographics).printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Staging the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loading dictionary data\n",
    "df_countryCodes = pd.read_csv('countries.csv')\n",
    "df_i94portCodes = pd.read_csv('i94portCodes.csv')\n",
    "\n",
    "# loading the csv files into pandas dataframes\n",
    "df_demographics = pd.read_csv('us-cities-demographics.csv', sep=';')\n",
    "df_temperature = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "\n",
    "# load the SAS data\n",
    "df_immigration=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Transforming the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Converting data dictionaries to views in our spark context in order to perform SQL operations with it\n",
    "\n",
    "spark_df_countryCodes = spark.createDataFrame(df_countryCodes)\n",
    "spark_df_countryCodes .createOrReplaceTempView(\"countryCodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# removing all entries with null values as they are either un-reported or outside the US\n",
    "\n",
    "df_i94portCodes = df_i94portCodes[~df_i94portCodes.state.isna()].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Excluding airports outside of the US. \n",
    "nonUSstates = ['CANADA', 'Canada', 'NETHERLANDS', 'NETH ANTILLES', 'THAILAND', 'ETHIOPIA', 'PRC', 'BERMUDA', 'COLOMBIA', 'ARGENTINA', 'MEXICO', \n",
    "               'BRAZIL', 'URUGUAY', 'IRELAND', 'GABON', 'BAHAMAS', 'MX', 'CAYMAN ISLAND', 'SEOUL KOREA', 'JAPAN', 'ROMANIA', 'INDONESIA',\n",
    "               'SOUTH AFRICA', 'ENGLAND', 'KENYA', 'TURK & CAIMAN', 'PANAMA', 'NEW GUINEA', 'ECUADOR', 'ITALY', 'EL SALVADOR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94portCodes = df_i94portCodes[~df_i94portCodes.state.isin(nonUSstates)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_i94portCodes = spark.createDataFrame(df_i94portCodes)\n",
    "spark_df_i94portCodes .createOrReplaceTempView(\"i94portCodes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration.createOrReplaceTempView(\"immig_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Removing all entry points into the united states that weren't via air travel \n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM immig_table\n",
    "WHERE i94mode = 1\n",
    "\"\"\").createOrReplaceTempView(\"immig_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dropping rows where the gender values entered is undefined\n",
    "\n",
    "spark.sql(\"\"\"SELECT * FROM immig_table WHERE gender IN ('F', 'M')\"\"\").createOrReplaceTempView(\"immig_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# converting the arrival dates into a useable value\n",
    "\n",
    "spark.sql(\"SELECT *, date_add(to_date('1960-01-01'), arrdate) AS arrival_date FROM immig_table\").createOrReplaceTempView(\"immig_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# converting the departure dates into a useable value\n",
    "\n",
    "spark.sql(\"\"\"SELECT *, CASE \n",
    "                        WHEN depdate >= 1.0 THEN date_add(to_date('1960-01-01'), depdate)\n",
    "                        WHEN depdate IS NULL THEN NULL\n",
    "                        ELSE 'N/A' END AS departure_date \n",
    "                        \n",
    "                FROM immig_table\"\"\").createOrReplaceTempView(\"immig_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using inner join to drop invalid codes\n",
    "#country of citizenship\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT im.*, cc.country AS citizenship_country\n",
    "FROM immig_table im\n",
    "INNER JOIN countryCodes cc\n",
    "ON im.i94cit = cc.code\n",
    "\"\"\").createOrReplaceTempView(\"immig_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dropping non useable values from country of residence\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT im.*, cc.country AS residence_country\n",
    "FROM immig_table im\n",
    "INNER JOIN countryCodes cc\n",
    "ON im.i94res = cc.code\n",
    "\"\"\").createOrReplaceTempView(\"immig_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Adding visa character string aggregation\n",
    "\n",
    "spark.sql(\"\"\"SELECT *, CASE \n",
    "                        WHEN i94visa = 1.0 THEN 'Business' \n",
    "                        WHEN i94visa = 2.0 THEN 'Pleasure'\n",
    "                        WHEN i94visa = 3.0 THEN 'Student'\n",
    "                        ELSE 'N/A' END AS visa_type \n",
    "                        \n",
    "                FROM immig_table\"\"\").createOrReplaceTempView(\"immig_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Adding entry_port names and entry port states to the view\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT im.*, pc.location AS entry_port, pc.state AS entry_port_state\n",
    "FROM immig_table im \n",
    "INNER JOIN i94portCodes pc\n",
    "ON im.i94port = pc.code\n",
    "\"\"\").createOrReplaceTempView(\"immig_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Computation of the age for each individual and adding it to the view\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT *, (2016-biryear) AS age \n",
    "FROM immig_table\n",
    "\"\"\").createOrReplaceTempView(\"immig_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert the immigration fact data into a spark dataframe\n",
    "\n",
    "fact_immigration = spark.sql(\"\"\"\n",
    "                        SELECT \n",
    "                            cicid, \n",
    "                            citizenship_country,\n",
    "                            residence_country,\n",
    "                            TRIM(UPPER (entry_port)) AS city,\n",
    "                            TRIM(UPPER (entry_port_state)) AS state,\n",
    "                            arrival_date,\n",
    "                            departure_date,\n",
    "                            age,\n",
    "                            visa_type,\n",
    "                            visatype AS detailed_visa_type\n",
    "\n",
    "                        FROM immig_table\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract all distinct dates from arrival and departure dates to create dimension table\n",
    "\n",
    "dim_time = spark.sql(\"\"\"\n",
    "SELECT DISTINCT arrival_date AS date\n",
    "FROM immig_table\n",
    "UNION\n",
    "SELECT DISTINCT departure_date AS date\n",
    "FROM immig_table\n",
    "WHERE departure_date IS NOT NULL\n",
    "\"\"\")\n",
    "dim_time.createOrReplaceTempView(\"dim_time_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract year, month, day, weekofyear, dayofweek and weekofyear from the date and insert all the values in the dim_time table;\n",
    "\n",
    "dim_time = spark.sql(\"\"\"\n",
    "SELECT date, YEAR(date) AS year, MONTH(date) AS month, DAY(date) AS day, WEEKOFYEAR(date) AS week, DAYOFWEEK(date) as weekday, DAYOFYEAR(date) year_day\n",
    "FROM dim_time_table\n",
    "ORDER BY date ASC\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Restricting data for the United States\n",
    "df_temperature = df_temperature[df_temperature['Country']=='United States'].copy()\n",
    "\n",
    "# Convert the date to datetime objects\n",
    "df_temperature['date'] = pd.to_datetime(df_temperature.dt)\n",
    "\n",
    "# Remove all dates prior to 1950\n",
    "df_temperature=df_temperature[df_temperature['date']>\"1950-01-01\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert the city names to upper case\n",
    "df_temperature.City = df_temperature.City.str.strip().str.upper() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert the dataframes from pandas to spark\n",
    "spark_df_temperature = spark.createDataFrame(df_temperature)\n",
    "spark_df_temperature .createOrReplaceTempView(\"temperature\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dim_temperature = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    DISTINCT date, city,\n",
    "    AVG(AverageTemperature) OVER (PARTITION BY date, City) AS average_temperature, \n",
    "    AVG(AverageTemperatureUncertainty)  OVER (PARTITION BY date, City) AS average_termperature_uncertainty\n",
    "    \n",
    "FROM temperature\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demographics.City = df_demographics.City.str.strip().str.upper()\n",
    "df_demographics['State Code'] = df_demographics['State Code'].str.strip().str.upper()\n",
    "df_demographics.Race = df_demographics.Race.str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert the dataframes from pandas to spark\n",
    "spark_df_demographics = spark.createDataFrame(df_demographics)\n",
    "spark_df_demographics.createOrReplaceTempView(\"demographics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# insert data into the demographics dim table\n",
    "dim_demographics = spark.sql(\"\"\"\n",
    "                                SELECT  City, \n",
    "                                        State, \n",
    "                                        `Median Age` AS median_age, \n",
    "                                        `Male Population` AS male_population, \n",
    "                                        `Female Population` AS female_population, \n",
    "                                        `Total Population` AS total_population, \n",
    "                                        `Foreign-born` AS foreign_born, \n",
    "                                        `Average Household Size` AS average_household_size, \n",
    "                                        `State Code` AS state_code, \n",
    "                                        Race, \n",
    "                                        Count\n",
    "                                FROM demographics\n",
    "                                \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Since the airport dataset contains a lot of nulls. We're loading the csv directly into a spark dataframe so we don't have to deal with converting pandas NaN into nulls\n",
    "\n",
    "spark_df_airports = spark.read.format(\"csv\").option(\"header\", \"true\").load('airport-codes_csv.csv')\n",
    "spark_df_airports.createOrReplaceTempView(\"airports\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# equivalent to the following pandas code:\n",
    "# df_airports = df_airports[df_airports['iso_country'].fillna('').str.upper().str.contains('US')].copy()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM airports\n",
    "WHERE iso_country IS NOT NULL\n",
    "AND UPPER(TRIM(iso_country)) LIKE 'US'\n",
    "\"\"\").createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#equivalent to the following pandas code:\n",
    "# excludedValues = ['closed', 'heliport', 'seaplane_base', 'balloonport']\n",
    "# df_airports = df_airports[~df_airports['type'].str.strip().isin(excludedValues)].copy()\n",
    "# df_airports = df_airports[~df_airports['municipality'].isna()].copy()\n",
    "# df_airports = df_airports[~df_airports['municipality'].isna()].copy()\n",
    "# df_airports['len'] = df_airports[\"iso_region\"].apply(len)\n",
    "# df_airports = df_airports[df_airports['len']==5].copy()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM airports\n",
    "WHERE LOWER(TRIM(type)) NOT IN ('closed', 'heliport', 'seaplane_base', 'balloonport')\n",
    "AND municipality IS NOT NULL\n",
    "AND LENGTH(iso_region) = 5\n",
    "\"\"\").createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dim_airports = spark.sql(\"\"\"\n",
    "SELECT TRIM(ident) AS ident, type, name, elevation_ft, SUBSTR(iso_region, 4) AS state, TRIM(UPPER(municipality)) AS municipality, iata_code\n",
    "FROM airports\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving the data in parquet format\n",
    "dim_demographics.write.parquet(\"dim_demographics\")\n",
    "dim_time.write.parquet(\"dim_time\")\n",
    "dim_airports.write.parquet(\"dim_airports\")\n",
    "dim_temperature.write.parquet(\"dim_temperature\")\n",
    "fact_immigration.write.parquet(\"fact_immigration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 4.2 Data Quality Checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "These are the data quality checks we'd perform to ensure the pipeline ran as expected:\n",
    "\n",
    "- [x] Integrity constraints on the relational database (e.g., unique key, data type, etc.)  \n",
    "- [x] Unit tests for the scripts to ensure they are doing the right thing  \n",
    "- [x] Source/Count checks to ensure completeness  \n",
    "- [x] Run Quality Checks  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creates or replaces a local temporary view with this\n",
    "dim_demographics.createOrReplaceTempView(\"dim_demographics\")\n",
    "dim_time.createOrReplaceTempView(\"dim_time\")\n",
    "dim_airports.createOrReplaceTempView(\"dim_airports\")\n",
    "dim_temperature.createOrReplaceTempView(\"dim_temperature\")\n",
    "fact_immigration.createOrReplaceTempView(\"fact_immigration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Check on the columns used as primary keys, if don't contain any null values. We define a function that could be incorporated in an automated data pipeline\n",
    "\n",
    "def nullValueCheck(spark_ctxt, tables_to_check):\n",
    "    \"\"\"\n",
    "    This function performs null value checks on specific columns of given tables received as parameters and raises a ValueError exception when null values are encountered.\n",
    "    It receives the following parameters:\n",
    "    spark_ctxt: spark context where the data quality check is to be performed\n",
    "    tables_to_check: A dictionary containing (table, columns) pairs specifying for each table, which column is to be checked for null values.   \n",
    "    \"\"\"  \n",
    "    for table in tables_to_check:\n",
    "        print(f\"Performing data quality check on table {table}...\")\n",
    "        for column in tables_to_check[table]:\n",
    "            returnedVal = spark_ctxt.sql(f\"\"\"SELECT COUNT(*) as nbr FROM {table} WHERE {column} IS NULL\"\"\")\n",
    "            if returnedVal.head()[0] > 0:\n",
    "                raise ValueError(f\"Data quality check failed! Found NULL values in {column} column!\")\n",
    "        print(f\"Table {table} passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Running data quality check on all the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing data quality check on table fact_immigration...\n",
      "Table fact_immigration passed.\n",
      "Performing data quality check on table dim_time...\n",
      "Table dim_time passed.\n",
      "Performing data quality check on table dim_demographics...\n",
      "Table dim_demographics passed.\n",
      "Performing data quality check on table dim_airports...\n",
      "Table dim_airports passed.\n",
      "Performing data quality check on table dim_temperature...\n",
      "Table dim_temperature passed.\n"
     ]
    }
   ],
   "source": [
    "#dictionary of tables and columns to be checked\n",
    "tables_to_check = { 'fact_immigration' : ['cicid'], 'dim_time':['date'], 'dim_demographics': ['City','state_code'], 'dim_airports':['ident'], 'dim_temperature':['date','City']}\n",
    "\n",
    "#We call our function on the spark context\n",
    "nullValueCheck(spark, tables_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|(count(1) - CAST(192 AS BIGINT))|\n",
      "+--------------------------------+\n",
      "|                               0|\n",
      "+--------------------------------+\n",
      "\n",
      "+--------------------------------------------+\n",
      "|(count(DISTINCT date) - CAST(192 AS BIGINT))|\n",
      "+--------------------------------------------+\n",
      "|                                           0|\n",
      "+--------------------------------------------+\n",
      "\n",
      "+----+\n",
      "|date|\n",
      "+----+\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#time dimension quality check\n",
    "\n",
    "#check the number of rows in our time table : 192 expected, this query would reflect 0 count if all is well.\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(*) - 192\n",
    "FROM dim_time\n",
    "\"\"\").show()\n",
    "\n",
    "# make sure each row has a distinct date key : 192 expected, this query would reflect 0 count if all is well.\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(DISTINCT date) - 192\n",
    "FROM dim_time\n",
    "\"\"\").show()\n",
    "\n",
    "# we could also subtract the result of one query from the other\n",
    "\n",
    "\n",
    "# and make sure all dates from the fact table are included in the time dimension (NULL is the expected result)\n",
    "spark.sql(\"\"\"\n",
    "SELECT DISTINCT date\n",
    "FROM dim_time\n",
    "\n",
    "MINUS\n",
    "\n",
    "(SELECT DISTINCT arrival_date AS date\n",
    "FROM immig_table\n",
    "UNION\n",
    "SELECT DISTINCT departure_date AS date\n",
    "FROM immig_table\n",
    "WHERE departure_date IS NOT NULL)\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|(count(DISTINCT cicid) - CAST(2165257 AS BIGINT))|\n",
      "+-------------------------------------------------+\n",
      "|                                                0|\n",
      "+-------------------------------------------------+\n",
      "\n",
      "+-------------------------------------------------+\n",
      "|(count(DISTINCT cicid) - CAST(2165257 AS BIGINT))|\n",
      "+-------------------------------------------------+\n",
      "|                                                0|\n",
      "+-------------------------------------------------+\n",
      "\n",
      "+------------------------------------+\n",
      "|(count(1) - CAST(2165257 AS BIGINT))|\n",
      "+------------------------------------+\n",
      "|                                   0|\n",
      "+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#immigration quality check\n",
    "\n",
    "# The number of primary key from the staging table (2165257 expected), this query would reflect 0 count if all is well.\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(distinct cicid) - 2165257\n",
    "FROM immig_table\n",
    "\"\"\").show()\n",
    "\n",
    "#should match the primary key count from the fact table (2165257 expected), this query would reflect 0 count if all is well.\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(distinct cicid) - 2165257\n",
    "FROM fact_immigration\n",
    "\"\"\").show()\n",
    "\n",
    "#and should match the row count from the fact table since it is also the primary key (2165257 expected), this query would reflect 0 count if all is well.\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(*) - 2165257\n",
    "FROM fact_immigration\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|(count(1) - CAST(2891 AS BIGINT))|\n",
      "+---------------------------------+\n",
      "|                                0|\n",
      "+---------------------------------+\n",
      "\n",
      "+----------------------------------------------------------+\n",
      "|(count(DISTINCT city, state, race) - CAST(2891 AS BIGINT))|\n",
      "+----------------------------------------------------------+\n",
      "|                                                         0|\n",
      "+----------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's validate the demographics dimension table (2891 expected), this query would reflect 0 count if all is well.\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(*) - 2891\n",
    "FROM dim_demographics\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(DISTINCT city, state, race) - 2891\n",
    "FROM dim_demographics\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|(count(1) - CAST(14529 AS BIGINT))|\n",
      "+----------------------------------+\n",
      "|                                 0|\n",
      "+----------------------------------+\n",
      "\n",
      "+-----------------------------------------------+\n",
      "|(count(DISTINCT ident) - CAST(14529 AS BIGINT))|\n",
      "+-----------------------------------------------+\n",
      "|                                              0|\n",
      "+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the primary key for airports (expected 14529), this query would reflect 0 count if all is well.\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(*) - 14529\n",
    "FROM dim_airports\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(DISTINCT ident) - 14529\n",
    "FROM dim_airports\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|(count(1) - CAST(189472 AS BIGINT))|\n",
      "+-----------------------------------+\n",
      "|                                  0|\n",
      "+-----------------------------------+\n",
      "\n",
      "+-----------------------------------------------------+\n",
      "|(count(DISTINCT date, city) - CAST(189472 AS BIGINT))|\n",
      "+-----------------------------------------------------+\n",
      "|                                                    0|\n",
      "+-----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check on city + date is our primary key for the temperature (expected 189472), this query would reflect 0 count if all is well.\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(*) - 189472\n",
    "FROM dim_temperature\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(DISTINCT date, city) - 189472\n",
    "FROM dim_temperature\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Validate the join on our dimensions and fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----------------+------+-----+------------+--------------+----+---------+------------------+\n",
      "|    cicid|citizenship_country|residence_country|  city|state|arrival_date|departure_date| age|visa_type|detailed_visa_type|\n",
      "+---------+-------------------+-----------------+------+-----+------------+--------------+----+---------+------------------+\n",
      "|4041803.0|            GERMANY|          GERMANY|BANGOR|   ME|  2016-04-22|    2016-05-07|49.0| Business|                B1|\n",
      "|4041804.0|            GERMANY|          GERMANY|BANGOR|   ME|  2016-04-22|          null|38.0| Business|                B1|\n",
      "+---------+-------------------+-----------------+------+-----+------------+--------------+----+---------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----+-------------+--------------------+------------+-----+------------+---------+\n",
      "|ident|         type|                name|elevation_ft|state|municipality|iata_code|\n",
      "+-----+-------------+--------------------+------------+-----+------------+---------+\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|   KS|       LEOTI|     null|\n",
      "| 00AK|small_airport|        Lowell Field|         450|   AK|ANCHOR POINT|     null|\n",
      "+-----+-------------+--------------------+------------+-----+------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validating join on airport and immigration\n",
    "\n",
    "fact_immigration.show(2)\n",
    "dim_airports.show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since a given city can have more than one airport and airport data is not provided in the immigration dataset.\n",
    "An ideal check would be on how many city & state combinations are common to the two datasets.\n",
    "\n",
    "We're looking at immigrant influx based on cities. Thus, we'd like to check whether the use of city and state combination works well to match the data between dim_airport and fact_immigration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|count(DISTINCT city, state)|\n",
      "+---------------------------+\n",
      "|                        151|\n",
      "+---------------------------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     102|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#here are the distinct combinations of city and state in our fact table\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(DISTINCT city, state)\n",
    "FROM fact_immigration\n",
    "\"\"\").show()\n",
    "\n",
    "# and the combinations of city and state that are common to both\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM\n",
    "(\n",
    "SELECT DISTINCT city, state\n",
    "FROM fact_immigration\n",
    ") fi\n",
    "INNER JOIN \n",
    "(\n",
    "SELECT DISTINCT municipality, state\n",
    "FROM dim_airports \n",
    ") da\n",
    "ON fi.city = da.municipality\n",
    "AND fi.state = da.state\n",
    "\"\"\").show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Around 66.66% of our data in the fact table can be paired with data in the airport fact table. \n",
    "\n",
    "Considering that the immigration table only includes one month of data, this is quite good.  \n",
    "Left join is prefered here.\n",
    "\n",
    "Let's check the same thing with the demographics table. \n",
    "We expect the results of the join to be lower since the table doesn't include all cities in the united states.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----------------+------+-----+------------+--------------+----+---------+------------------+\n",
      "|    cicid|citizenship_country|residence_country|  city|state|arrival_date|departure_date| age|visa_type|detailed_visa_type|\n",
      "+---------+-------------------+-----------------+------+-----+------------+--------------+----+---------+------------------+\n",
      "|4041803.0|            GERMANY|          GERMANY|BANGOR|   ME|  2016-04-22|    2016-05-07|49.0| Business|                B1|\n",
      "|4041804.0|            GERMANY|          GERMANY|BANGOR|   ME|  2016-04-22|          null|38.0| Business|                B1|\n",
      "+---------+-------------------+-----------------+------+-----+------------+--------------+----+---------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------+----------------------+----------+------------------+-----+\n",
      "|         City|        State|median_age|male_population|female_population|total_population|foreign_born|average_household_size|state_code|              Race|Count|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------+----------------------+----------+------------------+-----+\n",
      "|SILVER SPRING|     Maryland|      33.8|        40601.0|          41862.0|           82463|     30908.0|                   2.6|        MD|HISPANIC OR LATINO|25924|\n",
      "|       QUINCY|Massachusetts|      41.0|        44129.0|          49500.0|           93629|     32935.0|                  2.39|        MA|             WHITE|58723|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------+----------------------+----------+------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reading these two tables\n",
    "fact_immigration.show(2)\n",
    "dim_demographics.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|count(DISTINCT city, state)|\n",
      "+---------------------------+\n",
      "|                        151|\n",
      "+---------------------------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      69|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distinct combinations of city and state in our fact table\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(DISTINCT city, state)\n",
    "FROM fact_immigration\n",
    "\"\"\").show()\n",
    "\n",
    "# Combinations of city and state that are common to both the fact table and the demographics table\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM\n",
    "(\n",
    "SELECT DISTINCT city, state\n",
    "FROM fact_immigration\n",
    ") fi\n",
    "INNER JOIN \n",
    "(\n",
    "SELECT DISTINCT City, state_code\n",
    "FROM dim_demographics \n",
    ") da\n",
    "ON fi.city = da.City\n",
    "AND fi.state = da.state_code\n",
    "\"\"\").show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "~46% of the cities are accounted for in our demographics database.\n",
    "\n",
    "Let's filter out non existent city/state combinations from the data using a query similar to the one below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 1983869|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We use a count to see how many rows we would keep using this filter\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM fact_immigration\n",
    "WHERE CONCAT(city, state) IN (\n",
    "    SELECT CONCAT(fi.city, fi.state)\n",
    "    FROM\n",
    "    (\n",
    "        SELECT DISTINCT city, state\n",
    "        FROM fact_immigration\n",
    "    ) fi\n",
    "    INNER JOIN \n",
    "    (\n",
    "        SELECT DISTINCT municipality, state\n",
    "        FROM dim_airports \n",
    "    ) da\n",
    "    ON fi.city = da.municipality\n",
    "    AND fi.state = da.state\n",
    ")\n",
    "\"\"\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We filtered the database from 2165257 rows to 1983869 rows.  \n",
    "A difference of 181388 (8.38%)  \n",
    "However, we are assuming that our datasets are incomplete, especially the demographic data since it only includes cities with populations larger than 65,000 inhabitants and prefer to minimize the amount of data that is being left out of our final result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As the size of immigration data is quite huge (3mn for 1 month) along with demographic, temperature and airport dataset, Spark would be the base tech stack to work with, especially relevant if we were to process data over a longer period of time.\n",
    "\n",
    "We stated at the beginning of this project that we were interested in:\n",
    "\n",
    "* How temperature affects the volume of travellers ? \n",
    "* Which season of travel is most preferred ? \n",
    "* What sort of relationship is between the volume of travel and the number of entry ports (i.e. airports) ?\n",
    "* How the volume of travel and the demographics of various cities are dependent on each other ?\n",
    "\n",
    "Since these questions do not require a rapid update of our data. \n",
    "A monthly or quarterly update would be sufficient for such analysis\n",
    "\n",
    "****Alternate requirement scenarios:****\n",
    "\n",
    "How would our approach change if the problem had the following requireements:\n",
    "\n",
    "* The data was increased by 100x: Our data would be stored in an Amazon S3 bucket (instead of storing it in the EMR cluster along with the staging tables) and loaded to our staging tables. We would still use spark as it as our data processing platform since it is the best suited platform for very large datasets.\n",
    "* The data populates a dashboard that must be updated on a daily basis by 7am every day: We would use Apache Airflow to perform the ETL and data qualtiy validation.\n",
    "* The database needed to be accessed by 100+ people: Once the data is ready to be consumed, it would be stored in a postgres database on a redshift cluster that easily supports multiuser access.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
